# 备忘录
# 2022-11-3 12:01:26 主要功能更新：
# 1.分病毒类型输出正确率
# 2.舍弃每个epoch的val打印，保留训练过程中val正确率，拉通记录，作为最后的正确率（相当于取了训练过程中的val正确率的平均值，为了反映训练过程中的波动）
import os.path
import time

import torch.optim as optim
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.utils.data
import torch.utils.data.distributed
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.autograd import Variable
from torchvision.models import densenet121
import numpy as np




################# 修改数据集目录处 #################

# samples_root = r"/root/autodl-tmp/imgs/grey"
# samples_root = r"/root/autodl-tmp/imgs/hilbert"
# samples_root = r"/root/autodl-tmp/imgs/malkov"
# samples_root = r"/root/autodl-tmp/rgb_hill"
# samples_root = r"/root/autodl-tmp/3ChannelOrg"

##### new ####

# samples_root = r"/root/autodl-tmp/greyhil"
# samples_root = r"/root/autodl-tmp/three_chan_hil"
# samples_root = r"/root/autodl-tmp/rgb_hill_whiteplus"
# samples_root = r"C:\Users\17287\Desktop\rgb_hill_whiteplus"
samples_root = r"C:\Users\17287\Desktop\a"

################# 修改数据集目录处 #################

total_tensor = torch.zeros([1, 58]) #virus_num + 1

# 验证过程
def val(model, device, test_loader):
    model.eval()


    with torch.no_grad():
        for data, target in test_loader:
            data, target = Variable(data).to(device), Variable(target).to(device)
            output = model(data)
            # 如果所有概率小于某一个数字 / 如果所有概率相近 / /
            # _, pred = torch.max(output, 1)
            target = target.view(-1, 1)
            output = torch.cat((output, target), dim=1)
            global total_tensor
            total_tensor = torch.cat((total_tensor, output),dim=0)

            # for sin_target, sin_pred in zip(target, pred):
            #     if sin_target == sin_pred:
            #         correct_pred[classes_lables[sin_target]] += 1
            #     total_pred[classes_lables[sin_target]] += 1
            # loss = criterion(output, target) # 这一步中，没有留下loss，而是直接将正确率计入总的正确率中了
            # _, pred = torch.max(output.data, 1)
            #
            #
            # # 这里将“整体”的向量利用zip拆开了
            # for sin_target, sin_pred in zip(target, pred):
            #     if sin_target == sin_pred:
            #         correct_pred[classes_lables[sin_target]] += 1
            #     total_pred[classes_lables[sin_target]] += 1

        #     correct += torch.sum(pred == target)
        #     print_loss = loss.data.item()
        #     test_loss += print_loss
        # correct = correct.data.item()
        # acc = correct / total_num
        # avgloss = test_loss / len(test_loader)
        #
        # 取最大验证效果为最终验证效果
        # global val_acc
        # val_acc = acc if acc > val_acc else val_acc
        #
        # print('Val set  | Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        #     avgloss, correct, len(test_loader.dataset), 100 * acc))


# 训练
if __name__ == "__main__":

    time_begin = time.time()

    # 设置全局参数
    modellr = 0.01
    BATCH_SIZE = 32 # 64会超出当前 RTX 3080（10GB） 内存范围
    # DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    DEVICE = torch.device('cpu')

    if_normalize = True

    # 待分类的病毒总数
    virus_num = 0


    # 量化判定参数（用于量化展现训练效果）
    # 每2000条样本记录一次loss，多个epoch的数据融合在一起。
    # all_batch_lost_arr = []
    # val_acc = 0



    # 数据预处理
    if if_normalize:
        transform_train = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
        transform_test = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
    else:
        transform_train = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])

        transform_test = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])



    # 导入数据
    dataset_test = datasets.ImageFolder(os.path.join(samples_root,"test"), transform_test)
    test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)

    # 量化结果的参数
    correct_pred = {classname:0 for classname in dataset_test.classes}
    total_pred = {classname:0 for classname in dataset_test.classes}
    classes_lables = dataset_test.classes # list
    virus_num = len(dataset_test.classes)

    # 实例化模型并且移动到GPU
    # criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数
    model_ft = densenet121(pretrained=False)  # 调取已经选练好参数的模型
    num_ftrs = model_ft.classifier.in_features
    model_ft.classifier = nn.Linear(num_ftrs, virus_num)
    model_ft.to(DEVICE)
    model_ft.load_state_dict(torch.load('./a_model_params.pth'))


    #训练 & 验证
    print("Validation started...")
    val(model_ft, DEVICE, test_loader)

    #存储tensor用于分析
    total_tensor_np = total_tensor.numpy()
    np.save('a_1118', total_tensor_np)


    #存储一个列表即可，列表按照顺序来即可
    #这一部分相当于是存储了一个训练过程中val结果的平均值
    # sep_kind_correct = {classname:0 for classname in dataset_test.classes}
    # for key in correct_pred.keys():
    #     sep_kind_correct[key] = (correct_pred[key] / total_pred[key])
    # np.save("sep_kind_correct.npy", sep_kind_correct)



    # time_end = time.time()
    #
    # print("correct pred:",correct_pred.items())
    # print("total pred:", total_pred.items())
    # print("seperate kinds correct:", sep_kind_correct.items())
    # print("Total taken time: {:0.1f} min\n".format((time_end - time_begin)/60.0))