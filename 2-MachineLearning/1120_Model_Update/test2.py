# 备忘录
# 2022-11-3 12:01:26 主要功能更新：
# 1.分病毒类型输出正确率
# 2.舍弃每个epoch的val打印，保留训练过程中val正确率，拉通记录，作为最后的正确率（相当于取了训练过程中的val正确率的平均值，为了反映训练过程中的波动）
import os.path
import time

import torch.optim as optim
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.utils.data
import torch.utils.data.distributed
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.autograd import Variable
from torchvision.models import densenet121
import numpy as np




################# 修改数据集目录处 #################

# samples_root = r"/root/autodl-tmp/imgs/grey"
# samples_root = r"/root/autodl-tmp/imgs/hilbert"
# samples_root = r"/root/autodl-tmp/imgs/malkov"
# samples_root = r"/root/autodl-tmp/rgb_hill"
# samples_root = r"/root/autodl-tmp/3ChannelOrg"

##### new ####

# samples_root = r"/root/autodl-tmp/greyhil"
# samples_root = r"/root/autodl-tmp/three_chan_hil"
# samples_root = r"/root/autodl-tmp/rgb_hill_whiteplus"
samples_root = r"/root/autodl-tmp/a/a"
################# 修改数据集目录处 #################




# 如果两个教程里面都用了动态的梯度变换，那么这一个步骤应该是有用的。
def adjust_learning_rate(optimizer, epoch):
    """Sets the learning rate to the initial LR decayed by 10 every 30 epochs"""
    modellrnew = modellr * (0.1 ** (epoch // 50)) #向负取整商
    print("lr:", modellrnew)
    for param_group in optimizer.param_groups:
        param_group['lr'] = modellrnew


# 定义训练过程
# 一般的训练代码的书写思路：定义量化判定参数——训练——更新参数
# 可以将不同epoch之间的batch都视作统一分布（就好像batch都是在一个epoch内）——拉通的batch_loss
# 分阶段batch loss：
# 常用的量化判定参数：单个batch loss；平均batch loss；整个epoch的size
def train(model, device, train_loader, optimizer, epoch):
    model.train()

    # 声明batch量化参数
    sum_loss = 0 # 一个epoch做一个loss。但是参数更新是一个batch一次更新

    # 逐batch更新参数
    for batch_idx, (data, target) in enumerate(train_loader):

        # 模型参数更新
        data, target = Variable(data).to(device), Variable(target).to(device) #将数据在tensor角度、使用设备角度规范化
        output = model(data) # 一般会是个向量
        loss = criterion(output, target) # 一般会是个标量（float）.这里的参数传入是正确的
        # print(loss,loss.shape)
        optimizer.zero_grad() #梯度归0，避免梯度积累
        loss.backward() #反向传播，计算梯度
        optimizer.step() #参数更新

        # batch量化参数更新
        print_loss = loss.data.item() #得到损失
        sum_loss += print_loss

        # 打印信息
        if (batch_idx + 1) % 29 == 0:
            all_batch_lost_arr.append(sum_loss / (batch_idx + 1))

    # batch量化参数更新（补入余下的未满batch大小的样本们）
    ave_loss = sum_loss / len(train_loader) # len(train_loader)返回batch的个数，这一步算出的是平均每一batch的size
    all_batch_lost_arr.append(ave_loss)

    print('Train set| Average loss: {:.4f}'.format(ave_loss))


# 验证过程
def val(model, device, test_loader):
    model.eval()

    with torch.no_grad():
        for data, target in test_loader:
            data, target = Variable(data).to(device), Variable(target).to(device)
            output = model(data)
            # loss = criterion(output, target) # 这一步中，没有留下loss，而是直接将正确率计入总的正确率中了
            _, pred = torch.max(output.data, 1)


            # 这里将“整体”的向量利用zip拆开了
            for sin_target, sin_pred in zip(target, pred):
                if sin_target == sin_pred:
                    correct_pred[classes_lables[sin_target]] += 1
                total_pred[classes_lables[sin_target]] += 1

        #     correct += torch.sum(pred == target)
        #     print_loss = loss.data.item()
        #     test_loss += print_loss
        # correct = correct.data.item()
        # acc = correct / total_num
        # avgloss = test_loss / len(test_loader)
        #
        # 取最大验证效果为最终验证效果
        # global val_acc
        # val_acc = acc if acc > val_acc else val_acc
        #
        # print('Val set  | Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        #     avgloss, correct, len(test_loader.dataset), 100 * acc))


# 训练
if __name__ == "__main__":

    time_begin = time.time()

    # 设置全局参数
    modellr = 0.01
    BATCH_SIZE = 32 # 64会超出当前 RTX 3080（10GB） 内存范围
    EPOCHS = 7
    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    if_normalize = True

    # 待分类的病毒总数
    virus_num = 0


    # 量化判定参数（用于量化展现训练效果）
    # 每2000条样本记录一次loss，多个epoch的数据融合在一起。
    all_batch_lost_arr = []
    # val_acc = 0


    # 数据预处理
    if if_normalize:
        transform_train = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
        transform_test = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
    else:
        transform_train = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])

        transform_test = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])



    # 导入数据
    dataset_train = datasets.ImageFolder(os.path.join(samples_root,"train"), transform_train)
    dataset_test = datasets.ImageFolder(os.path.join(samples_root,"test"), transform_test)

    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True) #将Windows风格的数据集Python化（便于使用迭代器方法）
    test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)

    # 量化结果的参数
    correct_pred = {classname:0 for classname in dataset_test.classes}
    total_pred = {classname:0 for classname in dataset_test.classes}
    classes_lables = dataset_test.classes # list
    virus_num = len(dataset_test.classes)

    # 实例化模型并且移动到GPU
    criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数
    model_ft = densenet121(pretrained=True)  # 调取已经选练好参数的模型
    num_ftrs = model_ft.classifier.in_features
    model_ft.classifier = nn.Linear(num_ftrs, virus_num)
    model_ft.to(DEVICE)
    # 选择简单暴力的Adam优化器，学习率调低
    optimizer = optim.Adam(model_ft.parameters(), lr=modellr)



    #训练 & 验证
    print("Started...")
    for epoch in range(1, EPOCHS + 1):
        print("Epoch {}".format(epoch))
        adjust_learning_rate(optimizer, epoch) #这一步需要调整到项目适配的程度
        train(model_ft, DEVICE, train_loader, optimizer, epoch) # 参数是提取了所有病毒种类的特征吗？
    val(model_ft, DEVICE, test_loader)


    # 模型参数保存
    torch.save(model_ft.state_dict(), os.path.split(samples_root)[1]+'_model_params.pth')


    # 持久化存储
    # 存储可视化文件
    view = np.asarray(all_batch_lost_arr)
    np.save("all_batch_lost_arr_whiteplus.npy",view)

    # view = np.asarray(val_acc)
    # np.save("val_acc.npy",view)

    # 存储分类的正确率
    # 这一部分相当于是存储了一个训练过程中val结果的平均值
    sep_kind_correct = {classname:0 for classname in dataset_test.classes}
    for key in correct_pred.keys():
        sep_kind_correct[key] = (correct_pred[key] / total_pred[key])
    np.save("sep_kind_correct_whiteplus.npy", sep_kind_correct)



    time_end = time.time()
    print("Samples path:", samples_root)
    print("If using .Normalize: ", if_normalize)
    print("correct pred:",correct_pred.items())
    print("total pred:", total_pred.items())
    print("seperate kinds correct:", sep_kind_correct.items())
    print("Total taken time: {:0.1f} min\n".format((time_end - time_begin)/60.0))